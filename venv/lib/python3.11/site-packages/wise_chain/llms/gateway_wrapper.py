from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional

from langchain_core.callbacks import CallbackManagerForLLMRun
from langchain_core.language_models import LLM

from wise_chain.auth.authorizer import AuthSession, update_session
from wise_chain.constants import get_gateway_url
from wise_chain.gateway.call_gateway import call_gateway_llm


class GatewayLLMWrapper(LLM, ABC):
    model_id: str
    vendor: str
    endpoint: str
    team: str
    use_case: str
    timeout: int = 30
    service_or_user: str = 'user'
    ml_prod: bool = False
    base_uri: Optional[str] = None
    session: Optional[AuthSession] = None

    @property
    def _llm_type(self) -> str:
        return 'wise'

    @abstractmethod
    def _format_request(self, text: str, stop: Optional[List[str]] = None, **kwargs) -> Dict:
        raise NotImplementedError()

    @abstractmethod
    def _format_response(self, response: Dict) -> str:
        raise NotImplementedError()

    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        self.session = update_session(self.session, self.service_or_user, self.ml_prod)
        llm_gateway_url = self.base_uri or get_gateway_url(self.service_or_user, self.ml_prod)
        request = self._format_request(prompt, stop, **kwargs)
        url = f'{llm_gateway_url}/api/v1/{self.service_or_user}/{self.vendor}/{self.endpoint}'
        labels = {'team': self.team, 'use_case': self.use_case}
        response = call_gateway_llm(
            session=self.session, model_id=self.model_id, labels=labels, request=request, url=url, timeout=self.timeout
        )
        return self._format_response(response)
