from __future__ import annotations

from typing import ClassVar, Dict, List

from wise_chain.llm_registry import LLMRegistry
from wise_chain.llms.exceptions import RequestFormattingError, ResponseFormattingError
from wise_chain.llms.gateway_wrapper import GatewayLLMWrapper

GOOGLE_LLMS = [
    'gemini-2.5-flash',
    'gemini-2.5-pro',
    'gemini-2.0-flash-lite-001',
    'gemini-2.0-flash-001',
]


@LLMRegistry.register(GOOGLE_LLMS)
class Google(GatewayLLMWrapper):
    vendor: str = 'vertexai'
    endpoint: str = 'generate-content'

    example: ClassVar[dict] = {
        'model_id': 'gemini-1.5-pro-001',
        'labels': {'team': 'test-team', 'use_case': 'test-use-case'},
        'request': {
            'contents': [{'role': 'user', 'parts': [{'text': 'test'}]}],
            'generation_config': {'max_output_tokens': 2048, 'temperature': 0.9, 'top_p': 1},
        },
    }

    def _format_request(self, text: str, stop: List[str] | None = None, **kwargs) -> Dict:
        try:
            # Allow users to override contents
            if 'contents' in kwargs:
                contents = kwargs.pop('contents')

            else:
                contents = [{'role': 'user', 'parts': [{'text': text}]}]

            request = {
                'contents': contents,
                'generation_config': {
                    **kwargs,
                },
            }

        except Exception as ex:
            raise RequestFormattingError(f'Failed to format request: {ex}') from ex

        return request

    def _format_response(self, response: Dict) -> str:
        try:
            return str(response['candidates'][0]['content']['parts'][0]['text'])

        except Exception as ex:
            raise ResponseFormattingError(f'Failed to format response: {ex}') from ex
