from typing import Dict, List, Optional

from wise_chain.llm_registry import LLMRegistry
from wise_chain.llms.exceptions import RequestFormattingError, ResponseFormattingError
from wise_chain.llms.gateway_wrapper import GatewayLLMWrapper

AI21_LLMS = [
    'ai21.jamba-1-5-large-v1:0',
    'ai21.jamba-1-5-mini-v1:0',
]


@LLMRegistry.register(AI21_LLMS)
class AI21(GatewayLLMWrapper):
    vendor: str = 'bedrock'
    endpoint: str = 'invoke-model'

    def _format_request(self, text: str, stop: Optional[List[str]] = None, **kwargs) -> Dict:
        try:
            request = {'prompt': text, **kwargs}

            if stop:
                request['stopSequences'] = stop
        except Exception as ex:
            raise RequestFormattingError(f'Failed to format request: {ex}') from ex
        return request

    def _format_response(self, response: Dict) -> str:
        try:
            return str(response['completions'][0]['data']['text'])
        except Exception as ex:
            raise ResponseFormattingError(f'Failed to format response: {ex}') from ex
