import logging
from enum import Enum
from typing import Optional, Union

from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI

from wise_chain.auth.authorizer import AuthSession, update_session
from wise_chain.constants import get_gateway_url
from wise_chain.llms.anthropic import BEDROCK_CLAUDE_MODELS, CREDAL_CLAUDE_MODELS
from wise_chain.llms.openai import OPENAI_LLMS

ANTHROPIC_CHAT_MODELS = CREDAL_CLAUDE_MODELS + BEDROCK_CLAUDE_MODELS
OPENAI_CHAT_MODELS = OPENAI_LLMS

logger = logging.getLogger(__name__)


class ChatModelProvider(Enum):
    ANTHROPIC = 'anthropic'
    OPENAI = 'openai'


def load_chat_model(
    provider: ChatModelProvider,
    model_id: str,
    team: str,
    use_case: str,
    timeout: int = 30,
    service_or_user: str = 'user',
    ml_prod: bool = False,
    base_uri: Optional[str] = None,
) -> Union[ChatAnthropic, ChatOpenAI]:
    session = update_session(None, service_or_user, ml_prod)
    headers = _build_v2_headers(session=session, team=team, use_case=use_case, timeout=timeout)

    if provider == ChatModelProvider.ANTHROPIC:
        if model_id not in ANTHROPIC_CHAT_MODELS:
            logger.warning('model_id %s is not supported in wise-chain. Attempting anyway. ', model_id)

        if base_uri:
            base_url = f'{base_uri}/api/v2/anthropic'
        else:
            base_url = f'{get_gateway_url(service_or_user, ml_prod)}/api/v2/anthropic'

        return ChatAnthropic(
            model_name=model_id, base_url=base_url, api_key='dummy', default_headers=headers, timeout=timeout
        )

    elif provider == ChatModelProvider.OPENAI:
        if model_id not in OPENAI_CHAT_MODELS:
            logger.warning('model_id %s is not supported in wise-chain. Attempting anyway. ', model_id)

        if base_uri:
            base_url = f'{base_uri}/api/v2/openai/v1'
        else:
            base_url = f'{get_gateway_url(service_or_user, ml_prod)}/api/v2/openai/v1'

        return ChatOpenAI(model=model_id, base_url=base_url, api_key='dummy', default_headers=headers, timeout=timeout)

    else:
        raise ValueError(f'Unsupported provider: {provider}')


def _build_v2_headers(session: AuthSession, team: str, use_case: str, timeout: int) -> dict:
    headers = dict(session.session.headers)

    headers.update(
        {
            'x-wise-llm-gateway-team': team,
            'x-wise-llm-gateway-use-case': use_case,
            'x-envoy-upstream-rq-timeout-ms': str(timeout * 1000),
            'Content-Type': 'application/json',
        }
    )

    return headers
